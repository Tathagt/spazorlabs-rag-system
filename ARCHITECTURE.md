# ğŸ—ï¸ System Architecture

## Overview

The RAG system follows a modern microservices architecture with clear separation between frontend, backend, and data layers.

## Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         CLIENT LAYER                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚              React Frontend (Port 3000)                 â”‚ â”‚
â”‚  â”‚  â€¢ Drag & Drop Upload  â€¢ Query Interface               â”‚ â”‚
â”‚  â”‚  â€¢ Results Display     â€¢ Source Citations              â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â”‚ HTTP/REST
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      APPLICATION LAYER                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚           FastAPI Backend (Port 8000)                   â”‚ â”‚
â”‚  â”‚                                                          â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
â”‚  â”‚  â”‚   Upload     â”‚  â”‚    Query     â”‚  â”‚    Stats     â”‚ â”‚ â”‚
â”‚  â”‚  â”‚   Handler    â”‚  â”‚   Handler    â”‚  â”‚   Handler    â”‚ â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
â”‚  â”‚                                                          â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚
â”‚  â”‚  â”‚         Document Processing Pipeline             â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  1. Text Extraction (PyPDF2)                     â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  2. Chunking (LangChain)                         â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  3. Embedding Generation (OpenAI)                â”‚  â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                   â”‚
                    â–¼                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      DATA LAYER          â”‚  â”‚    EXTERNAL SERVICES     â”‚
â”‚                          â”‚  â”‚                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚    ChromaDB        â”‚  â”‚  â”‚  â”‚   OpenAI API       â”‚  â”‚
â”‚  â”‚  Vector Database   â”‚  â”‚  â”‚  â”‚                    â”‚  â”‚
â”‚  â”‚                    â”‚  â”‚  â”‚  â”‚  â€¢ Embeddings      â”‚  â”‚
â”‚  â”‚  â€¢ Embeddings      â”‚  â”‚  â”‚  â”‚  â€¢ GPT-4o-mini     â”‚  â”‚
â”‚  â”‚  â€¢ Metadata        â”‚  â”‚  â”‚  â”‚                    â”‚  â”‚
â”‚  â”‚  â€¢ Cosine Search   â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Component Details

### 1. Frontend (React)

**Responsibilities:**
- User interface for document upload
- Query input and submission
- Results visualization with citations
- Real-time feedback and loading states

**Key Technologies:**
- React 18 with Hooks
- Axios for HTTP requests
- React Dropzone for file uploads
- React Markdown for answer rendering

**Files:**
- `frontend/src/App.js` - Main application component
- `frontend/src/App.css` - Styling
- `frontend/public/index.html` - HTML template

### 2. Backend (FastAPI)

**Responsibilities:**
- RESTful API endpoints
- Document processing pipeline
- Vector database management
- LLM orchestration

**Key Technologies:**
- FastAPI for async API
- PyPDF2 for PDF parsing
- LangChain for text splitting
- ChromaDB client for vector operations

**Files:**
- `backend/main.py` - Main application with all endpoints
- `backend/requirements.txt` - Python dependencies
- `backend/Dockerfile` - Container configuration

### 3. Vector Database (ChromaDB)

**Responsibilities:**
- Store document embeddings
- Perform similarity search
- Manage metadata

**Configuration:**
- Distance metric: Cosine similarity
- Storage: DuckDB + Parquet (persistent)
- Collection: "documents"

### 4. External Services

**OpenAI API:**
- **Embeddings**: text-embedding-3-small (1536 dimensions)
- **LLM**: gpt-4o-mini for answer generation
- **Usage**: ~100ms per embedding, ~2-3s per completion

## Data Flow

### Upload Flow

```
1. User uploads PDF/TXT
   â†“
2. Frontend sends file to /upload
   â†“
3. Backend extracts text (PyPDF2)
   â†“
4. Text split into chunks (LangChain)
   â†“
5. Generate embeddings (OpenAI)
   â†“
6. Store in ChromaDB with metadata
   â†“
7. Return success + chunk count
```

### Query Flow

```
1. User submits question
   â†“
2. Frontend sends to /query
   â†“
3. Generate question embedding (OpenAI)
   â†“
4. Search ChromaDB (cosine similarity)
   â†“
5. Retrieve top-k chunks + metadata
   â†“
6. Build context from chunks
   â†“
7. Generate answer with GPT (OpenAI)
   â†“
8. Return answer + sources + confidence
   â†“
9. Frontend displays with citations
```

## Scalability Considerations

### Current Architecture (Demo/MVP)
- Single-instance deployment
- In-memory ChromaDB
- Synchronous processing
- **Suitable for**: Demos, small teams, low traffic

### Production Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Load Balancerâ”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
   â”Œâ”€â”€â”€â”´â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”
   â–¼        â–¼        â–¼        â–¼
â”Œâ”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”
â”‚API-1â”‚  â”‚API-2â”‚  â”‚API-3â”‚  â”‚API-Nâ”‚
â””â”€â”€â”¬â”€â”€â”˜  â””â”€â”€â”¬â”€â”€â”˜  â””â”€â”€â”¬â”€â”€â”˜  â””â”€â”€â”¬â”€â”€â”˜
   â”‚        â”‚        â”‚        â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
      â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”
      â”‚   Redis   â”‚ (Cache)
      â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
            â”‚
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  Managed Vector â”‚
   â”‚  DB (Pinecone)  â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Improvements:**
- Horizontal scaling with load balancer
- Redis caching for embeddings
- Managed vector DB (Pinecone/Weaviate)
- Async task queue (Celery)
- CDN for frontend

## Performance Optimization

### Latency Breakdown
- **Text Extraction**: 50-200ms (PDF size dependent)
- **Chunking**: 10-50ms
- **Embedding Generation**: 100ms per chunk
- **Vector Search**: <50ms
- **LLM Generation**: 2-3s
- **Total**: ~3-4s per query

### Optimization Strategies

1. **Caching**
   - Cache embeddings for repeated chunks
   - Cache common queries
   - Use Redis for distributed cache

2. **Batching**
   - Batch embedding requests
   - Process multiple chunks in parallel

3. **Indexing**
   - Use HNSW index in ChromaDB
   - Optimize chunk size for retrieval

4. **Model Selection**
   - Use smaller embedding models for dev
   - Consider local models for privacy

## Security Architecture

### Current Implementation
- Environment-based API key management
- CORS configuration
- Input validation

### Production Recommendations
- API rate limiting
- Authentication/Authorization (JWT)
- Request signing
- Encryption at rest
- HTTPS only
- API key rotation
- Audit logging

## Monitoring & Observability

### Metrics to Track
- Request latency (p50, p95, p99)
- Error rates
- OpenAI API usage
- Vector DB query performance
- Document processing time
- Storage usage

### Recommended Tools
- **Logging**: Structured logging with JSON
- **Metrics**: Prometheus + Grafana
- **Tracing**: OpenTelemetry
- **Alerts**: PagerDuty/Slack integration

## Deployment Architecture

### Development
```
Local Machine
â”œâ”€â”€ Backend (localhost:8000)
â”œâ”€â”€ Frontend (localhost:3000)
â””â”€â”€ ChromaDB (local file)
```

### Production
```
Cloud Infrastructure
â”œâ”€â”€ Frontend (Vercel/Netlify)
â”œâ”€â”€ Backend (Railway/Render)
â”‚   â”œâ”€â”€ Auto-scaling
â”‚   â””â”€â”€ Health checks
â””â”€â”€ Vector DB (Managed service)
```

## Future Enhancements

1. **Multi-modal Support**
   - Image document processing
   - Audio transcription

2. **Advanced Features**
   - Conversation memory
   - Multi-document comparison
   - Automatic summarization

3. **Enterprise Features**
   - Multi-tenancy
   - Role-based access
   - Custom model fine-tuning
   - Analytics dashboard

## Technology Choices Rationale

| Component | Choice | Rationale |
|-----------|--------|-----------|
| Backend Framework | FastAPI | Async support, auto docs, type safety |
| Vector DB | ChromaDB | Easy setup, good for demos, Python-native |
| Embeddings | OpenAI | High quality, fast, well-supported |
| LLM | GPT-4o-mini | Cost-effective, fast, accurate |
| Frontend | React | Component-based, large ecosystem |
| Deployment | Railway/Vercel | Easy setup, free tier, good DX |